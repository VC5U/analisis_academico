{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd037deb",
   "metadata": {},
   "source": [
    "Práctica: Modelos Supervisado y No Supervisado\n",
    "Dataset: academic_performance_master.csv\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "1. IMPORTACIÓN DE LIBRERÍAS\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04604a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698343d",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    " 2. CARGA Y EXPLORACIÓN DE DATOS\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba3163",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"2. CARGA Y EXPLORACIÓN DE DATOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv('academic_performance_master.csv')\n",
    "print(f\"Dimensión del dataset: {df.shape}\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nInformación del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nEstadísticas descriptivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(f\"\\nValores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nValores duplicados: {df.duplicated().sum()}\")\n",
    "\n",
    "# Variables clave\n",
    "print(f\"\\nDistribución de variables categóricas:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed294da",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    " 3. PREPARACIÓN DEL DATASET\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f00588",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3. PREPARACIÓN DEL DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Copiar dataset para limpieza\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Verificar y manejar valores nulos\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        if df_clean[col].dtype == 'object':\n",
    "            df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "        else:\n",
    "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "\n",
    "print(f\"Valores nulos después de limpieza: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# Crear variable objetivo: Aprobado (1) o Reprobado (0)\n",
    "# Suponemos que aprueba con nota final >= 70\n",
    "df_clean['Aprobado'] = (df_clean['Nota_final'] >= 70).astype(int)\n",
    "print(f\"\\nDistribución de la variable objetivo:\")\n",
    "print(df_clean['Aprobado'].value_counts())\n",
    "print(f\"Proporción: {df_clean['Aprobado'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Codificar variables categóricas\n",
    "label_encoders = {}\n",
    "for col in df_clean.select_dtypes(include=['object']).columns:\n",
    "    if col != 'Estudiante_ID':  # No codificar ID\n",
    "        le = LabelEncoder()\n",
    "        df_clean[col] = le.fit_transform(df_clean[col])\n",
    "        label_encoders[col] = le\n",
    "        print(f\"Columna '{col}' codificada\")\n",
    "\n",
    "# Preparar datos para modelo supervisado\n",
    "# Excluir columnas no relevantes\n",
    "exclude_cols = ['Estudiante_ID', 'Nota_final', 'Aprobado']\n",
    "feature_cols = [col for col in df_clean.columns if col not in exclude_cols]\n",
    "\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean['Aprobado']\n",
    "\n",
    "# Estandarizar características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nDivisión de datos:\")\n",
    "print(f\"Train: {X_train.shape[0]} muestras\")\n",
    "print(f\"Test: {X_test.shape[0]} muestras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca36787",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    " 4. MODELO SUPERVISADO (CLASIFICACIÓN)\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc852534",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"4. MODELO SUPERVISADO - REGRESIÓN LOGÍSTICA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Entrenar modelo\n",
    "model_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = model_lr.predict(X_test)\n",
    "y_pred_proba = model_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy del modelo: {accuracy:.4f}\")\n",
    "print(f\"\\nMatriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "print(f\"\\nReporte de clasificación:\")\n",
    "print(class_report)\n",
    "\n",
    "# Importancia de características\n",
    "if hasattr(model_lr, 'coef_'):\n",
    "    importance = pd.DataFrame({\n",
    "        'Variable': feature_cols,\n",
    "        'Importancia': np.abs(model_lr.coef_[0])\n",
    "    }).sort_values('Importancia', ascending=False)\n",
    "    \n",
    "    print(f\"\\nImportancia de variables:\")\n",
    "    print(importance)\n",
    "\n",
    "# Visualización de métricas\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matriz de confusión\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Matriz de Confusión')\n",
    "axes[0].set_xlabel('Predicción')\n",
    "axes[0].set_ylabel('Real')\n",
    "\n",
    "# Importancia de variables\n",
    "importance_sorted = importance.sort_values('Importancia')\n",
    "axes[1].barh(importance_sorted['Variable'], importance_sorted['Importancia'])\n",
    "axes[1].set_title('Importancia de Variables')\n",
    "axes[1].set_xlabel('Importancia absoluta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('metricas_supervisado.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89204f13",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    " 5. MODELO NO SUPERVISADO (CLUSTERING)\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6eb0b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"5. MODELO NO SUPERVISADO - K-MEANS CLUSTERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Seleccionar características para clustering\n",
    "clustering_features = ['Asistencia', 'Nota_final', 'Tareas_entregadas']\n",
    "X_cluster = df_clean[clustering_features].copy()\n",
    "\n",
    "# Estandarizar\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "# Método del codo para determinar k óptimo\n",
    "inertias = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Graficar método del codo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertias, 'bo-')\n",
    "plt.xlabel('Número de Clusters (k)')\n",
    "plt.ylabel('Inercia')\n",
    "plt.title('Método del Codo para K óptimo')\n",
    "plt.grid(True)\n",
    "plt.savefig('metodo_codo.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Aplicar K-means con 3 clusters\n",
    "k_optimal = 3\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "df_clean['Cluster'] = clusters\n",
    "\n",
    "print(f\"\\nDistribución de clusters (K={k_optimal}):\")\n",
    "print(df_clean['Cluster'].value_counts().sort_index())\n",
    "\n",
    "# Estadísticas por cluster\n",
    "print(f\"\\nEstadísticas por cluster:\")\n",
    "cluster_stats = df_clean.groupby('Cluster')[['Asistencia', 'Nota_final', 'Tareas_entregadas', 'Aprobado']].mean()\n",
    "print(cluster_stats)\n",
    "\n",
    "# Interpretación de clusters\n",
    "print(f\"\\nInterpretación de clusters:\")\n",
    "for i in range(k_optimal):\n",
    "    cluster_data = df_clean[df_clean['Cluster'] == i]\n",
    "    print(f\"\\nCluster {i} (n={len(cluster_data)}):\")\n",
    "    print(f\"  - Asistencia promedio: {cluster_data['Asistencia'].mean():.1f}%\")\n",
    "    print(f\"  - Nota final promedio: {cluster_data['Nota_final'].mean():.1f}\")\n",
    "    print(f\"  - Tasa de aprobación: {cluster_data['Aprobado'].mean()*100:.1f}%\")\n",
    "    \n",
    "    if cluster_data['Aprobado'].mean() > 0.8:\n",
    "        print(f\"  - Perfil: Estudiantes exitosos\")\n",
    "    elif cluster_data['Aprobado'].mean() > 0.5:\n",
    "        print(f\"  - Perfil: Estudiantes regulares\")\n",
    "    else:\n",
    "        print(f\"  - Perfil: Estudiantes en riesgo\")\n",
    "\n",
    "# Visualización de clusters\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Gráfico 1: Asistencia vs Nota_final\n",
    "scatter1 = axes[0].scatter(df_clean['Asistencia'], df_clean['Nota_final'], \n",
    "                          c=df_clean['Cluster'], cmap='viridis', alpha=0.6)\n",
    "axes[0].scatter(kmeans.cluster_centers_[:, 0]*scaler_cluster.scale_[0] + scaler_cluster.mean_[0],\n",
    "               kmeans.cluster_centers_[:, 1]*scaler_cluster.scale_[1] + scaler_cluster.mean_[1],\n",
    "               s=200, c='red', marker='X', label='Centroides')\n",
    "axes[0].set_xlabel('Asistencia (%)')\n",
    "axes[0].set_ylabel('Nota Final')\n",
    "axes[0].set_title('Clustering: Asistencia vs Nota Final')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 2: Tareas_entregadas vs Nota_final\n",
    "scatter2 = axes[1].scatter(df_clean['Tareas_entregadas'], df_clean['Nota_final'], \n",
    "                          c=df_clean['Cluster'], cmap='viridis', alpha=0.6)\n",
    "axes[1].scatter(kmeans.cluster_centers_[:, 2]*scaler_cluster.scale_[2] + scaler_cluster.mean_[2],\n",
    "               kmeans.cluster_centers_[:, 1]*scaler_cluster.scale_[1] + scaler_cluster.mean_[1],\n",
    "               s=200, c='red', marker='X', label='Centroides')\n",
    "axes[1].set_xlabel('Tareas Entregadas')\n",
    "axes[1].set_ylabel('Nota Final')\n",
    "axes[1].set_title('Clustering: Tareas Entregadas vs Nota Final')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.savefig('clustering_resultados.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c40be",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    " 6. ANÁLISIS COMPARATIVO\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1a2d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"6. ANÁLISIS COMPARATIVO Y CONCLUSIONES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nCOMPARACIÓN DE MODELOS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"MODELO SUPERVISADO (Regresión Logística):\")\n",
    "print(\"  • Tipo: Clasificación binaria\")\n",
    "print(f\"  • Precisión: {accuracy:.2%}\")\n",
    "print(\"  • Variables importantes: Asistencia, Tareas entregadas\")\n",
    "print(\"  • Fortalezas: Buen poder predictivo, interpretable\")\n",
    "print(\"  • Limitaciones: Asume relación lineal\")\n",
    "\n",
    "print(\"\\nMODELO NO SUPERVISADO (K-means):\")\n",
    "print(\"  • Tipo: Clustering\")\n",
    "print(f\"  • Clusters identificados: {k_optimal}\")\n",
    "print(\"  • Patrones encontrados: Grupos con comportamientos similares\")\n",
    "print(\"  • Fortalezas: Descubre patrones ocultos, no requiere etiquetas\")\n",
    "print(\"  • Limitaciones: Requiere definir k, sensible a outliers\")\n",
    "\n",
    "print(\"\\n¿QUÉ MODELO ES MEJOR?\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Depende del objetivo:\")\n",
    "print(\"1. Para PREDECIR aprobación: Modelo Supervisado\")\n",
    "print(\"   • Proporciona probabilidades específicas\")\n",
    "print(\"   • Alta precisión para identificar estudiantes en riesgo\")\n",
    "print(\"   • Útil para intervenciones tempranas\")\n",
    "\n",
    "print(\"\\n2. Para ENTENDER patrones: Modelo No Supervisado\")\n",
    "print(\"   • Identifica perfiles de estudiantes\")\n",
    "print(\"   • Útil para estrategias pedagógicas diferenciadas\")\n",
    "print(\"   • Ayuda en la segmentación para tutorías\")\n",
    "\n",
    "print(\"\\nRECOMENDACIÓN:\")\n",
    "print(\"Usar ambos modelos complementariamente:\")\n",
    "print(\"- K-means para segmentar a los estudiantes en grupos\")\n",
    "print(\"- Regresión logística para predecir riesgo dentro de cada grupo\")\n",
    "print(\"- Esto permite intervenciones personalizadas más efectivas\")\n",
    "\n",
    "# Guardar datos procesados\n",
    "df_clean.to_csv('datos_procesados.csv', index=False)\n",
    "print(\"\\nDatos procesados guardados en 'datos_procesados.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PRÁCTICA COMPLETADA EXITOSAMENTE\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
