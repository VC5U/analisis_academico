{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0689ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "PR√ÅCTICA COMPLETA - MODELOS SUPERVISADO Y NO SUPERVISADO\n",
    "An√°lisis Predictivo del Rendimiento Acad√©mico\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# 1. IMPORTACI√ìN DE LIBRER√çAS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CARGA Y EXPLORACI√ìN DE DATOS\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"2. CARGA Y EXPLORACI√ìN DE DATOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Cargar dataset\n",
    "    df = pd.read_csv('academic_performance_master.csv')\n",
    "    print(f\"‚úÖ Dataset cargado exitosamente\")\n",
    "    print(f\"   ‚Ä¢ Dimensi√≥n: {df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "    print(f\"   ‚Ä¢ Columnas: {list(df.columns)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERROR: No se encontr√≥ 'academic_performance_master.csv'\")\n",
    "    print(\"üìù Creando dataset de ejemplo para continuar...\")\n",
    "    \n",
    "    # Crear datos de ejemplo\n",
    "    np.random.seed(42)\n",
    "    n_estudiantes = 150\n",
    "    \n",
    "    datos = {\n",
    "        'Estudiante_ID': [f'EST{i:03d}' for i in range(n_estudiantes)],\n",
    "        'Nombre': [f'Estudiante_{i}' for i in range(n_estudiantes)],\n",
    "        'Edad': np.random.randint(18, 30, n_estudiantes),\n",
    "        'Genero': np.random.choice(['M', 'F'], n_estudiantes),\n",
    "        'Carrera': np.random.choice(['Ingenier√≠a', 'Medicina', 'Derecho', 'Administraci√≥n'], n_estudiantes),\n",
    "        'Semestre': np.random.randint(1, 10, n_estudiantes),\n",
    "        'Asistencia': np.random.normal(85, 10, n_estudiantes).clip(60, 100).astype(int),\n",
    "        'Tareas_entregadas': np.random.randint(5, 20, n_estudiantes),\n",
    "        'Participacion_clase': np.random.normal(7, 2, n_estudiantes).clip(0, 10).astype(int),\n",
    "        'Horas_estudio': np.random.normal(12, 4, n_estudiantes).clip(2, 25).astype(int),\n",
    "        'Nota_parcial1': np.random.normal(75, 15, n_estudiantes).clip(30, 100).astype(int),\n",
    "        'Nota_parcial2': np.random.normal(72, 18, n_estudiantes).clip(30, 100).astype(int),\n",
    "        'Nota_final': np.random.normal(70, 20, n_estudiantes).clip(0, 100).astype(int),\n",
    "        'Nivel': np.random.choice(['Licenciatura', 'Maestr√≠a'], n_estudiantes, p=[0.8, 0.2])\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(datos)\n",
    "    df.to_csv('academic_performance_master.csv', index=False)\n",
    "    print(\"‚úÖ Dataset de ejemplo creado y guardado\")\n",
    "\n",
    "# Mostrar informaci√≥n b√°sica\n",
    "print(f\"\\nüìä INFORMACI√ìN DEL DATASET:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nüìà ESTAD√çSTICAS DESCRIPTIVAS:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(f\"\\nüîç VALORES NULOS POR COLUMNA:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nüîÑ VALORES DUPLICADOS: {df.duplicated().sum()}\")\n",
    "\n",
    "print(f\"\\nüìã DISTRIBUCI√ìN DE VARIABLES CATEG√ìRICAS:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if col != 'Estudiante_ID':\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df[col].value_counts().head())\n",
    "\n",
    "# ============================================================================\n",
    "# 3. PREPARACI√ìN DEL DATASET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"3. PREPARACI√ìN DEL DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 3.1 Manejo de valores nulos\n",
    "print(\"üîß MANEJO DE VALORES NULOS:\")\n",
    "for col in df_clean.columns:\n",
    "    null_count = df_clean[col].isnull().sum()\n",
    "    if null_count > 0:\n",
    "        if df_clean[col].dtype == 'object':\n",
    "            df_clean[col].fillna('Desconocido', inplace=True)\n",
    "            print(f\"   ‚Ä¢ {col}: {null_count} nulos ‚Üí 'Desconocido'\")\n",
    "        else:\n",
    "            median_val = df_clean[col].median()\n",
    "            df_clean[col].fillna(median_val, inplace=True)\n",
    "            print(f\"   ‚Ä¢ {col}: {null_count} nulos ‚Üí {median_val:.2f}\")\n",
    "\n",
    "# 3.2 Eliminar duplicados\n",
    "if df_clean.duplicated().sum() > 0:\n",
    "    df_clean.drop_duplicates(inplace=True)\n",
    "    print(f\"\\nüóëÔ∏è  Eliminados {df.duplicated().sum()} registros duplicados\")\n",
    "\n",
    "# 3.3 Crear variable objetivo\n",
    "print(\"\\nüéØ CREANDO VARIABLE OBJETIVO:\")\n",
    "df_clean['Aprobado'] = (df_clean['Nota_final'] >= 70).astype(int)\n",
    "print(f\"   ‚Ä¢ Aprobados (1): {df_clean['Aprobado'].sum()} estudiantes\")\n",
    "print(f\"   ‚Ä¢ Reprobados (0): {len(df_clean) - df_clean['Aprobado'].sum()} estudiantes\")\n",
    "print(f\"   ‚Ä¢ Tasa de aprobaci√≥n: {df_clean['Aprobado'].mean()*100:.1f}%\")\n",
    "\n",
    "# 3.4 Preparar datos num√©ricos para modelo\n",
    "print(\"\\nüìä PREPARANDO DATOS PARA MODELOS:\")\n",
    "\n",
    "# Seleccionar columnas num√©ricas relevantes\n",
    "numeric_features = ['Asistencia', 'Tareas_entregadas', 'Participacion_clase', \n",
    "                    'Horas_estudio', 'Nota_parcial1', 'Nota_parcial2']\n",
    "\n",
    "# Verificar qu√© columnas existen realmente\n",
    "existing_features = [col for col in numeric_features if col in df_clean.columns]\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas num√©ricas encontradas: {existing_features}\")\n",
    "\n",
    "# Si no hay suficientes caracter√≠sticas, usar todas las num√©ricas\n",
    "if len(existing_features) < 3:\n",
    "    existing_features = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # Excluir columnas no relevantes\n",
    "    exclude = ['Aprobado', 'Nota_final']\n",
    "    existing_features = [col for col in existing_features if col not in exclude]\n",
    "    print(f\"   ‚Ä¢ Usando todas las num√©ricas: {existing_features}\")\n",
    "\n",
    "X = df_clean[existing_features]\n",
    "y = df_clean['Aprobado']\n",
    "\n",
    "# 3.5 Estandarizar caracter√≠sticas\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3.6 Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüìà DIVISI√ìN DE DATOS:\")\n",
    "print(f\"   ‚Ä¢ Conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"   ‚Ä¢ Conjunto de prueba: {X_test.shape[0]} muestras\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas: {X_train.shape[1]} variables\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. MODELO SUPERVISADO - CLASIFICACI√ìN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"4. MODELO SUPERVISADO - REGRESI√ìN LOG√çSTICA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 4.1 Entrenar modelo\n",
    "print(\"üöÄ ENTRENANDO MODELO DE REGRESI√ìN LOG√çSTICA...\")\n",
    "model_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# 4.2 Predicciones\n",
    "y_pred = model_lr.predict(X_test)\n",
    "y_pred_proba = model_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 4.3 M√©tricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ MODELO ENTRENADO EXITOSAMENTE\")\n",
    "print(f\"\\nüìä M√âTRICAS DEL MODELO:\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Precisi√≥n: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(f\"\\nüìã MATRIZ DE CONFUSI√ìN:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(f\"\\nüìÑ REPORTE DE CLASIFICACI√ìN:\")\n",
    "print(class_report)\n",
    "\n",
    "# 4.4 Importancia de caracter√≠sticas\n",
    "if hasattr(model_lr, 'coef_'):\n",
    "    importance = pd.DataFrame({\n",
    "        'Variable': existing_features,\n",
    "        'Importancia': np.abs(model_lr.coef_[0])\n",
    "    }).sort_values('Importancia', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüîù IMPORTANCIA DE VARIABLES:\")\n",
    "    print(importance.to_string(index=False))\n",
    "\n",
    "# 4.5 Visualizaci√≥n\n",
    "print(\"\\nüé® GENERANDO VISUALIZACIONES...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Reprobado', 'Aprobado'],\n",
    "            yticklabels=['Reprobado', 'Aprobado'], \n",
    "            ax=axes[0])\n",
    "axes[0].set_title('Matriz de Confusi√≥n')\n",
    "axes[0].set_xlabel('Predicci√≥n')\n",
    "axes[0].set_ylabel('Real')\n",
    "\n",
    "# Importancia de variables\n",
    "importance_sorted = importance.sort_values('Importancia')\n",
    "axes[1].barh(importance_sorted['Variable'], importance_sorted['Importancia'])\n",
    "axes[1].set_title('Importancia de Variables')\n",
    "axes[1].set_xlabel('Importancia Absoluta')\n",
    "axes[1].set_ylabel('Variable')\n",
    "\n",
    "# Distribuci√≥n de probabilidades\n",
    "axes[2].hist(y_pred_proba[y_test == 0], alpha=0.5, label='Reprobados', bins=20, color='red')\n",
    "axes[2].hist(y_pred_proba[y_test == 1], alpha=0.5, label='Aprobados', bins=20, color='green')\n",
    "axes[2].set_title('Distribuci√≥n de Probabilidades Predichas')\n",
    "axes[2].set_xlabel('Probabilidad de Aprobar')\n",
    "axes[2].set_ylabel('Frecuencia')\n",
    "axes[2].legend()\n",
    "axes[2].axvline(x=0.5, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('metricas_supervisado.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Visualizaci√≥n guardada como 'metricas_supervisado.png'\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. MODELO NO SUPERVISADO - CLUSTERING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"5. MODELO NO SUPERVISADO - K-MEANS CLUSTERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 5.1 Seleccionar caracter√≠sticas para clustering\n",
    "print(\"üîç PREPARANDO DATOS PARA CLUSTERING...\")\n",
    "clustering_features = ['Asistencia', 'Nota_final', 'Tareas_entregadas']\n",
    "# Verificar qu√© caracter√≠sticas est√°n disponibles\n",
    "available_features = [f for f in clustering_features if f in df_clean.columns]\n",
    "\n",
    "if len(available_features) < 2:\n",
    "    # Si no hay suficientes, usar las primeras 3 num√©ricas\n",
    "    available_features = df_clean.select_dtypes(include=[np.number]).columns.tolist()[:3]\n",
    "    print(f\"‚ö†Ô∏è  Usando caracter√≠sticas alternativas: {available_features}\")\n",
    "\n",
    "X_cluster = df_clean[available_features].copy()\n",
    "\n",
    "# 5.2 Estandarizar\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "# 5.3 M√©todo del codo\n",
    "print(\"üìà APLICANDO M√âTODO DEL CODO...\")\n",
    "inertias = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Determinar k √≥ptimo (simple)\n",
    "inertia_diffs = np.diff(inertias)\n",
    "k_optimal = np.argmax(inertia_diffs) + 2  # +2 porque empezamos en k=1\n",
    "\n",
    "print(f\"   ‚Ä¢ K √≥ptimo sugerido: {k_optimal}\")\n",
    "\n",
    "# 5.4 Aplicar K-means\n",
    "print(f\"üéØ APLICANDO K-MEANS CON K={k_optimal}...\")\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "df_clean['Cluster'] = clusters\n",
    "\n",
    "print(f\"\\nüìä DISTRIBUCI√ìN DE CLUSTERS:\")\n",
    "print(df_clean['Cluster'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nüìà ESTAD√çSTICAS POR CLUSTER:\")\n",
    "cluster_stats = df_clean.groupby('Cluster').agg({\n",
    "    'Nota_final': ['mean', 'std', 'min', 'max'],\n",
    "    'Asistencia': ['mean', 'std'],\n",
    "    'Tareas_entregadas': ['mean', 'std'],\n",
    "    'Aprobado': 'mean'\n",
    "})\n",
    "\n",
    "print(cluster_stats.round(2))\n",
    "\n",
    "# 5.5 Interpretaci√≥n\n",
    "print(f\"\\nüë• INTERPRETACI√ìN DE CLUSTERS:\")\n",
    "for i in range(k_optimal):\n",
    "    cluster_data = df_clean[df_clean['Cluster'] == i]\n",
    "    print(f\"\\n   CLUSTER {i} (n={len(cluster_data)}):\")\n",
    "    print(f\"     ‚Ä¢ Nota final: {cluster_data['Nota_final'].mean():.1f}\")\n",
    "    print(f\"     ‚Ä¢ Asistencia: {cluster_data['Asistencia'].mean():.1f}%\")\n",
    "    print(f\"     ‚Ä¢ Tareas: {cluster_data['Tareas_entregadas'].mean():.1f}\")\n",
    "    print(f\"     ‚Ä¢ Aprobaci√≥n: {cluster_data['Aprobado'].mean()*100:.1f}%\")\n",
    "\n",
    "# 5.6 Visualizaci√≥n\n",
    "print(\"\\nüé® GENERANDO VISUALIZACIONES DE CLUSTERING...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# M√©todo del codo\n",
    "axes[0].plot(k_range, inertias, 'bo-')\n",
    "axes[0].axvline(x=k_optimal, color='r', linestyle='--', label=f'K √≥ptimo = {k_optimal}')\n",
    "axes[0].set_xlabel('N√∫mero de Clusters (k)')\n",
    "axes[0].set_ylabel('Inercia')\n",
    "axes[0].set_title('M√©todo del Codo')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico de clusters\n",
    "if len(available_features) >= 2:\n",
    "    scatter = axes[1].scatter(df_clean[available_features[0]], \n",
    "                             df_clean[available_features[1]], \n",
    "                             c=df_clean['Cluster'], cmap='viridis', alpha=0.6, s=50)\n",
    "    axes[1].set_xlabel(available_features[0])\n",
    "    axes[1].set_ylabel(available_features[1])\n",
    "    axes[1].set_title(f'Clustering: {available_features[0]} vs {available_features[1]}')\n",
    "    plt.colorbar(scatter, ax=axes[1], label='Cluster')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('clustering_resultados.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ Visualizaci√≥n guardada como 'clustering_resultados.png'\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. AN√ÅLISIS COMPARATIVO Y CONCLUSIONES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"6. AN√ÅLISIS COMPARATIVO Y CONCLUSIONES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä COMPARACI√ìN DE MODELOS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"üîÆ MODELO SUPERVISADO (Regresi√≥n Log√≠stica):\")\n",
    "print(f\"   ‚Ä¢ Tipo: Clasificaci√≥n binaria\")\n",
    "print(f\"   ‚Ä¢ Precisi√≥n: {accuracy:.2%}\")\n",
    "print(f\"   ‚Ä¢ Variables importantes: {importance.head(3)['Variable'].tolist()}\")\n",
    "print(f\"   ‚Ä¢ Fortalezas: Buen poder predictivo, interpretable\")\n",
    "print(f\"   ‚Ä¢ Limitaciones: Asume relaci√≥n lineal\")\n",
    "\n",
    "print(f\"\\nüîç MODELO NO SUPERVISADO (K-means):\")\n",
    "print(f\"   ‚Ä¢ Tipo: Clustering\")\n",
    "print(f\"   ‚Ä¢ Clusters identificados: {k_optimal}\")\n",
    "print(f\"   ‚Ä¢ Patrones encontrados: Grupos con comportamientos similares\")\n",
    "print(f\"   ‚Ä¢ Fortalezas: Descubre patrones ocultos, no requiere etiquetas\")\n",
    "print(f\"   ‚Ä¢ Limitaciones: Requiere definir k, sensible a outliers\")\n",
    "\n",
    "print(f\"\\nü§î ¬øQU√â MODELO ES MEJOR?\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   Depende del objetivo:\")\n",
    "print(f\"   1. Para PREDECIR aprobaci√≥n: Modelo Supervisado\")\n",
    "print(f\"      ‚Ä¢ Proporciona probabilidades espec√≠ficas\")\n",
    "print(f\"      ‚Ä¢ Alta precisi√≥n para identificar estudiantes en riesgo\")\n",
    "print(f\"      ‚Ä¢ √ötil para intervenciones tempranas\")\n",
    "\n",
    "print(f\"\\n   2. Para ENTENDER patrones: Modelo No Supervisado\")\n",
    "print(f\"      ‚Ä¢ Identifica perfiles de estudiantes\")\n",
    "print(f\"      ‚Ä¢ √ötil para estrategias pedag√≥gicas diferenciadas\")\n",
    "print(f\"      ‚Ä¢ Ayuda en la segmentaci√≥n para tutor√≠as\")\n",
    "\n",
    "print(f\"\\nüöÄ RECOMENDACI√ìN:\")\n",
    "print(f\"   Usar ambos modelos complementariamente:\")\n",
    "print(f\"   - K-means para segmentar a los estudiantes en grupos\")\n",
    "print(f\"   - Regresi√≥n log√≠stica para predecir riesgo dentro de cada grupo\")\n",
    "print(f\"   - Esto permite intervenciones personalizadas m√°s efectivas\")\n",
    "\n",
    "# Guardar datos procesados\n",
    "df_clean.to_csv('datos_procesados.csv', index=False)\n",
    "print(f\"\\nüíæ Datos procesados guardados en 'datos_procesados.csv'\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ PR√ÅCTICA COMPLETADA EXITOSAMENTE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìÅ Archivos generados:\")\n",
    "print(f\"   ‚Ä¢ metricas_supervisado.png\")\n",
    "print(f\"   ‚Ä¢ clustering_resultados.png\")\n",
    "print(f\"   ‚Ä¢ datos_procesados.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
