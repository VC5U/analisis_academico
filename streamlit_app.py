import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.cluster import KMeans
import plotly.express as px
import plotly.graph_objects as go
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="An√°lisis Acad√©mico - ML",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("üéì An√°lisis Predictivo del Rendimiento Acad√©mico")
st.markdown("""
**Modelos Supervisado y No Supervisado** para predecir y entender el rendimiento estudiantil
""")

# Sidebar para navegaci√≥n
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2232/2232688.png", width=100)
    st.title("Navegaci√≥n")
    
    section = st.radio(
        "Selecciona una secci√≥n:",
        ["üìä Exploraci√≥n de Datos", 
         "ü§ñ Modelo Supervisado", 
         "üîç Modelo No Supervisado",
         "üìà Comparaci√≥n",
         "üîÆ Predicci√≥n"]
    )
    
    st.markdown("---")
    st.markdown("### Configuraci√≥n")
    
    if section == "ü§ñ Modelo Supervisado":
        test_size = st.slider("Tama√±o del conjunto de prueba:", 0.1, 0.5, 0.3, 0.05)
        limite_aprobacion = st.slider("L√≠mite para aprobar:", 50, 90, 70, 5)
        
    elif section == "üîç Modelo No Supervisado":
        n_clusters = st.slider("N√∫mero de clusters:", 2, 6, 3)
        feature_x = st.selectbox("Variable X:", ["Asistencia", "Nota_final", "Tareas_entregadas"])
        feature_y = st.selectbox("Variable Y:", ["Nota_final", "Asistencia", "Tareas_entregadas"])

# Funci√≥n para cargar y preparar datos
@st.cache_data
def cargar_y_preparar_datos(limite_aprobacion=70):
    try:
        df = pd.read_csv('academic_performance_master.csv')
        
        # Verificar columnas disponibles
        st.sidebar.info(f"üìä Dataset: {df.shape[0]} filas, {df.shape[1]} columnas")
        
        # Mostrar columnas reales en debug
        debug_cols = st.sidebar.checkbox("Mostrar columnas del dataset", value=False)
        if debug_cols:
            st.sidebar.write("Columnas disponibles:", list(df.columns))
        
        # Crear copia para limpieza
        df_clean = df.copy()
        
        # Manejar valores nulos
        for col in df_clean.columns:
            if df_clean[col].isnull().sum() > 0:
                if df_clean[col].dtype == 'object':
                    df_clean[col].fillna('Desconocido', inplace=True)
                else:
                    df_clean[col].fillna(df_clean[col].median(), inplace=True)
        
        # Buscar columna de nota (puede tener diferentes nombres)
        nota_cols = [col for col in df_clean.columns if 'nota' in col.lower() or 'Nota' in col]
        if nota_cols:
            nota_col = nota_cols[0]
            st.sidebar.success(f"‚úÖ Columna de nota encontrada: '{nota_col}'")
            
            # Crear variable objetivo
            df_clean['Aprobado'] = (df_clean[nota_col] >= limite_aprobacion).astype(int)
            
            # Verificar distribuci√≥n de clases
            aprobados = df_clean['Aprobado'].sum()
            total = len(df_clean)
            st.sidebar.info(f"üìä Distribuci√≥n: {aprobados} aprobados ({aprobados/total*100:.1f}%)")
            
            if aprobados == 0 or aprobados == total:
                st.sidebar.warning(f"‚ö†Ô∏è Solo hay una clase en los datos. Ajusta el l√≠mite de aprobaci√≥n.")
                
        else:
            st.sidebar.error("‚ùå No se encontr√≥ columna de nota en el dataset")
            # Crear variable objetivo ficticia para continuar
            df_clean['Aprobado'] = np.random.choice([0, 1], size=len(df_clean), p=[0.3, 0.7])
        
        return df, df_clean
        
    except Exception as e:
        st.sidebar.error(f"‚ùå Error al cargar datos: {str(e)}")
        
        # Crear datos de ejemplo
        np.random.seed(42)
        n_estudiantes = 200
        
        datos = {
            'Estudiante': [f'EST{i:03d}' for i in range(n_estudiantes)],
            'Nombre': [f'Estudiante_{i}' for i in range(n_estudiantes)],
            'Asistencia': np.random.normal(85, 10, n_estudiantes).clip(60, 100).astype(int),
            'Tareas_entregadas': np.random.randint(5, 20, n_estudiantes),
            'Participacion_clase': np.random.normal(7, 2, n_estudiantes).clip(0, 10).astype(int),
            'Horas_estudio': np.random.normal(12, 4, n_estudiantes).clip(2, 25).astype(int),
            'Nota_parcial1': np.random.normal(75, 15, n_estudiantes).clip(30, 100).astype(int),
            'Nota_parcial2': np.random.normal(72, 18, n_estudiantes).clip(30, 100).astype(int),
            'Nota_final': np.random.normal(70, 20, n_estudiantes).clip(0, 100).astype(int),
            'Nivel': np.random.choice(['Licenciatura', 'Maestr√≠a'], n_estudiantes, p=[0.8, 0.2])
        }
        
        df = pd.DataFrame(datos)
        df_clean = df.copy()
        df_clean['Aprobado'] = (df_clean['Nota_final'] >= limite_aprobacion).astype(int)
        
        st.sidebar.warning("‚ö†Ô∏è Usando datos de ejemplo")
        return df, df_clean

# Cargar datos seg√∫n la secci√≥n
if section == "ü§ñ Modelo Supervisado":
    limite = st.session_state.get('limite_aprobacion', 70)
    if 'limite_aprobacion' in st.session_state:
        limite = st.session_state.limite_aprobacion
    df, df_clean = cargar_y_preparar_datos(limite)
else:
    df, df_clean = cargar_y_preparar_datos()

# ============================================================================
# SECCI√ìN 1: EXPLORACI√ìN DE DATOS
# ============================================================================
if section == "üìä Exploraci√≥n de Datos":
    st.header("üìä Exploraci√≥n del Dataset")
    
    # Pesta√±as
    tab1, tab2, tab3 = st.tabs(["üìã Vista General", "üìà An√°lisis", "üîç Calidad"])
    
    with tab1:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("Primeros registros")
            st.dataframe(df.head(10), use_container_width=True, height=300)
            
            st.subheader("√öltimos registros")
            st.dataframe(df.tail(5), use_container_width=True, height=200)
        
        with col2:
            st.subheader("Informaci√≥n general")
            st.metric("Total de estudiantes", len(df))
            st.metric("Variables", len(df.columns))
            
            if 'Aprobado' in df_clean.columns:
                aprobados = df_clean['Aprobado'].sum()
                total = len(df_clean)
                st.metric("Estudiantes que aprueban", aprobados)
                st.metric("Tasa de aprobaci√≥n", f"{aprobados/total*100:.1f}%")
            
            # Mostrar tipos de datos
            st.subheader("Tipos de datos")
            tipos = pd.DataFrame(df.dtypes, columns=['Tipo'])
            st.dataframe(tipos, use_container_width=True)
    
    with tab2:
        col1, col2 = st.columns(2)
        
        with col1:
            # Buscar columna num√©rica para histograma
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            if len(numeric_cols) > 0:
                col_selected = st.selectbox("Selecciona variable para histograma:", numeric_cols)
                
                fig = px.histogram(df, x=col_selected, nbins=30,
                                  title=f'Distribuci√≥n de {col_selected}',
                                  color_discrete_sequence=['#636EFA'])
                fig.update_layout(xaxis_title=col_selected, yaxis_title="Frecuencia")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("No hay columnas num√©ricas para analizar")
        
        with col2:
            # Boxplot
            if len(numeric_cols) > 0:
                col_box = st.selectbox("Selecciona variable para boxplot:", numeric_cols, 
                                      key='boxplot_select')
                
                fig = px.box(df, y=col_box, 
                            title=f'Boxplot de {col_box}',
                            color_discrete_sequence=['#00CC96'])
                st.plotly_chart(fig, use_container_width=True)
        
        # Matriz de correlaci√≥n
        st.subheader("Matriz de Correlaci√≥n")
        
        if len(numeric_cols) > 1:
            corr_matrix = df[numeric_cols].corr()
            
            fig = px.imshow(corr_matrix, 
                           text_auto='.2f',
                           aspect="auto",
                           color_continuous_scale='RdBu',
                           title='Correlaci√≥n entre variables')
            st.plotly_chart(fig, use_container_width=True)
            
            # Top correlaciones
            st.subheader("Correlaciones m√°s fuertes")
            if 'Nota_final' in corr_matrix.columns:
                correlaciones = corr_matrix['Nota_final'].abs().sort_values(ascending=False)
                correlaciones = correlaciones[correlaciones.index != 'Nota_final']
                
                top_corr = correlaciones.head(5)
                st.write(top_corr)
    
    with tab3:
        col1, col2 = st.columns(2)
        
        with col1:
            # Valores nulos
            st.subheader("Valores Nulos")
            null_counts = df.isnull().sum()
            null_df = pd.DataFrame({
                'Variable': null_counts.index,
                'Valores nulos': null_counts.values,
                '% Nulos': (null_counts.values / len(df) * 100).round(2)
            })
            null_df = null_df[null_df['Valores nulos'] > 0]
            
            if len(null_df) > 0:
                st.dataframe(null_df, use_container_width=True)
            else:
                st.success("‚úÖ No hay valores nulos")
        
        with col2:
            # Duplicados
            st.subheader("Registros Duplicados")
            dup_count = df.duplicated().sum()
            if dup_count > 0:
                st.warning(f"‚ö†Ô∏è {dup_count} registros duplicados encontrados")
                
                if st.button("Mostrar duplicados"):
                    duplicates = df[df.duplicated(keep=False)]
                    st.dataframe(duplicates, use_container_width=True)
            else:
                st.success("‚úÖ No hay registros duplicados")
            
            # Valores √∫nicos
            st.subheader("Valores √önicos por Columna")
            unique_counts = df.nunique()
            unique_df = pd.DataFrame({
                'Variable': unique_counts.index,
                'Valores √∫nicos': unique_counts.values
            })
            st.dataframe(unique_df.head(10), use_container_width=True)

# ============================================================================
# SECCI√ìN 2: MODELO SUPERVISADO
# ============================================================================
elif section == "ü§ñ Modelo Supervisado":
    st.header("ü§ñ Modelo de Clasificaci√≥n Supervisada")
    
    # Actualizar l√≠mite en sesi√≥n
    st.session_state.limite_aprobacion = limite_aprobacion
    
    # Recargar datos con nuevo l√≠mite
    df, df_clean = cargar_y_preparar_datos(limite_aprobacion)
    
    # Verificar que tenemos ambas clases
    if 'Aprobado' not in df_clean.columns:
        st.error("No se pudo crear la variable objetivo 'Aprobado'")
        st.stop()
    
    clase_counts = df_clean['Aprobado'].value_counts()
    if len(clase_counts) < 2:
        st.warning(f"""
        ‚ö†Ô∏è **Problema**: Solo hay una clase en los datos ({clase_counts.index[0]})
        
        **Causas posibles:**
        1. El l√≠mite de aprobaci√≥n ({limite_aprobacion}) es muy alto/bajo
        2. Todos los estudiantes tienen notas similares
        3. El dataset tiene un desbalance extremo
        
        **Soluci√≥n:**
        - Ajusta el l√≠mite de aprobaci√≥n en la barra lateral
        - O usa datos de ejemplo (selecciona en barra lateral)
        """)
        
        # Mostrar estad√≠sticas de notas
        nota_cols = [col for col in df_clean.columns if 'nota' in col.lower() or 'Nota' in col]
        if nota_cols:
            st.subheader("Estad√≠sticas de Notas")
            nota_col = nota_cols[0]
            st.write(f"Columna de nota: {nota_col}")
            st.write(df_clean[nota_col].describe())
        
        st.stop()
    
    # Preparar datos para modelo
    st.subheader("Preparaci√≥n de Datos")
    
    # Seleccionar caracter√≠sticas num√©ricas
    numeric_features = df_clean.select_dtypes(include=[np.number]).columns.tolist()
    
    # Excluir columnas no relevantes
    exclude_features = ['Aprobado']
    for col in df_clean.columns:
        if 'nota' in col.lower() or 'Nota' in col:
            exclude_features.append(col)
    
    features = [col for col in numeric_features if col not in exclude_features]
    
    if len(features) == 0:
        st.error("No hay caracter√≠sticas num√©ricas para entrenar el modelo")
        st.stop()
    
    st.write(f"**Caracter√≠sticas seleccionadas:** {len(features)} variables")
    st.write(features)
    
    X = df_clean[features]
    y = df_clean['Aprobado']
    
    # Mostrar distribuci√≥n de clases
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total muestras", len(X))
    with col2:
        st.metric("Clase 0 (Reprobados)", (y == 0).sum())
    with col3:
        st.metric("Clase 1 (Aprobados)", (y == 1).sum())
    
    # Estandarizar y dividir
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=test_size, random_state=42, stratify=y
    )
    
    # Entrenar modelo
    st.subheader("Entrenamiento del Modelo")
    
    try:
        model = LogisticRegression(random_state=42, max_iter=1000)
        model.fit(X_train, y_train)
        
        # Predicciones y m√©tricas
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        conf_matrix = confusion_matrix(y_test, y_pred)
        
        # Mostrar resultados
        st.success(f"‚úÖ Modelo entrenado exitosamente")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Accuracy", f"{accuracy:.2%}")
        
        with col2:
            precision = conf_matrix[1,1] / (conf_matrix[1,1] + conf_matrix[0,1]) if (conf_matrix[1,1] + conf_matrix[0,1]) > 0 else 0
            st.metric("Precisi√≥n", f"{precision:.2%}")
        
        with col3:
            recall = conf_matrix[1,1] / (conf_matrix[1,1] + conf_matrix[1,0]) if (conf_matrix[1,1] + conf_matrix[1,0]) > 0 else 0
            st.metric("Recall", f"{recall:.2%}")
        
        # Matriz de confusi√≥n
        st.subheader("Matriz de Confusi√≥n")
        fig = px.imshow(conf_matrix,
                       text_auto=True,
                       color_continuous_scale='Blues',
                       labels=dict(x="Predicci√≥n", y="Real", color="Cantidad"),
                       x=['Reprobado', 'Aprobado'],
                       y=['Reprobado', 'Aprobado'],
                       title=f'Accuracy: {accuracy:.2%}')
        st.plotly_chart(fig, use_container_width=True)
        
        # Reporte
        st.subheader("Reporte de Clasificaci√≥n")
        report = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report).transpose()
        st.dataframe(report_df, use_container_width=True)
        
        # Importancia de caracter√≠sticas
        st.subheader("Importancia de Caracter√≠sticas")
        if hasattr(model, 'coef_'):
            importance = pd.DataFrame({
                'Variable': features,
                'Importancia': np.abs(model.coef_[0])
            }).sort_values('Importancia', ascending=False)
            
            fig = px.bar(importance, 
                        x='Importancia', 
                        y='Variable',
                        orientation='h',
                        title='Importancia de Variables',
                        color='Importancia',
                        color_continuous_scale='Viridis')
            st.plotly_chart(fig, use_container_width=True)
            
            st.dataframe(importance, use_container_width=True)
    
    except Exception as e:
        st.error(f"‚ùå Error al entrenar modelo: {str(e)}")

# ============================================================================
# SECCI√ìN 3: MODELO NO SUPERVISADO
# ============================================================================
elif section == "üîç Modelo No Supervisado":
    st.header("üîç Clustering de Estudiantes")
    
    # Verificar caracter√≠sticas disponibles
    available_features = [col for col in ['Asistencia', 'Nota_final', 'Tareas_entregadas'] 
                         if col in df_clean.columns]
    
    if len(available_features) < 2:
        # Usar primeras columnas num√©ricas
        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()
        available_features = numeric_cols[:min(3, len(numeric_cols))]
        st.warning(f"Usando caracter√≠sticas disponibles: {available_features}")
    
    if len(available_features) < 2:
        st.error("Se necesitan al menos 2 caracter√≠sticas num√©ricas para clustering")
        st.stop()
    
    # Verificar que las caracter√≠sticas seleccionadas existan
    if feature_x not in available_features:
        feature_x = available_features[0]
    if feature_y not in available_features:
        feature_y = available_features[1] if len(available_features) > 1 else available_features[0]
    
    # Seleccionar datos para clustering
    cluster_features = list(set([feature_x, feature_y]))
    X_cluster = df_clean[cluster_features].copy()
    
    # Eliminar valores nulos
    X_cluster = X_cluster.dropna()
    
    if len(X_cluster) < n_clusters:
        st.error(f"No hay suficientes datos ({len(X_cluster)}) para {n_clusters} clusters")
        st.stop()
    
    # Aplicar K-means
    scaler_cluster = StandardScaler()
    X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)
    
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X_cluster_scaled)
    
    df_clustered = df_clean.copy()
    # Asegurar que los √≠ndices coincidan
    df_clustered = df_clustered.loc[X_cluster.index].copy()
    df_clustered['Cluster'] = clusters
    
    # M√©todo del codo
    st.subheader("M√©todo del Codo para Determinar K √ìptimo")
    inertias = []
    k_range = range(1, 11)
    
    for k in k_range:
        kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans_temp.fit(X_cluster_scaled)
        inertias.append(kmeans_temp.inertia_)
    
    fig1 = px.line(x=list(k_range), y=inertias, 
                  title='M√©todo del Codo',
                  labels={'x': 'N√∫mero de Clusters', 'y': 'Inercia'},
                  markers=True)
    fig1.add_vline(x=n_clusters, line_dash="dash", line_color="red",
                  annotation_text=f"K seleccionado = {n_clusters}")
    st.plotly_chart(fig1, use_container_width=True)
    
    # Visualizaci√≥n de clusters
    st.subheader(f"Visualizaci√≥n de Clusters ({n_clusters} grupos)")
    
    # Preparar hover data
    hover_columns = []
    for col in df_clustered.columns:
        if col not in cluster_features + ['Cluster']:
            # Tomar solo algunas columnas para hover
            if len(hover_columns) < 3:  # M√°ximo 3 columnas adicionales
                hover_columns.append(col)
    
    fig2 = px.scatter(df_clustered, 
                     x=feature_x,
                     y=feature_y,
                     color='Cluster',
                     title=f'Clustering: {feature_x} vs {feature_y}',
                     hover_data=hover_columns[:3],  # Limitar a 3 columnas
                     color_continuous_scale='viridis')
    
    # A√±adir centroides
    centroids_descaled = scaler_cluster.inverse_transform(kmeans.cluster_centers_)
    centroids_df = pd.DataFrame(centroids_descaled, columns=cluster_features)
    centroids_df['Cluster'] = range(n_clusters)
    
    fig2.add_trace(go.Scatter(
        x=centroids_df[feature_x],
        y=centroids_df[feature_y],
        mode='markers',
        marker=dict(symbol='x', size=15, color='red', line=dict(width=2)),
        name='Centroides',
        hoverinfo='skip'
    ))
    
    st.plotly_chart(fig2, use_container_width=True)
    
    # Estad√≠sticas por cluster
    st.subheader("Estad√≠sticas por Cluster")
    
    # Seleccionar columnas para estad√≠sticas
    stats_cols = cluster_features.copy()
    if 'Aprobado' in df_clustered.columns:
        stats_cols.append('Aprobado')
    
    cluster_stats = df_clustered.groupby('Cluster')[stats_cols].agg(['mean', 'std', 'count']).round(2)
    
    # Formatear mejor la tabla
    cluster_stats_flat = pd.DataFrame()
    for col in stats_cols:
        for stat in ['mean', 'std']:
            if (col, stat) in cluster_stats.columns:
                cluster_stats_flat[f'{col}_{stat}'] = cluster_stats[(col, stat)]
    
    st.dataframe(cluster_stats_flat, use_container_width=True)
    
    # Distribuci√≥n de clusters
    st.subheader("Distribuci√≥n de Estudiantes por Cluster")
    cluster_counts = df_clustered['Cluster'].value_counts().sort_index()
    
    fig3 = px.bar(x=cluster_counts.index.astype(str), 
                  y=cluster_counts.values,
                  title='N√∫mero de Estudiantes por Cluster',
                  labels={'x': 'Cluster', 'y': 'Cantidad de Estudiantes'},
                  color=cluster_counts.index.astype(str))
    st.plotly_chart(fig3, use_container_width=True)
    
    # Interpretaci√≥n
    st.subheader("Interpretaci√≥n de Clusters")
    
    for cluster_id in range(n_clusters):
        with st.expander(f"Cluster {cluster_id} - {cluster_counts.get(cluster_id, 0)} estudiantes"):
            cluster_data = df_clustered[df_clustered['Cluster'] == cluster_id]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Caracter√≠sticas promedio:**")
                for feature in stats_cols[:3]:  # Mostrar primeras 3
                    if feature in cluster_data.columns:
                        avg = cluster_data[feature].mean()
                        st.write(f"- {feature}: {avg:.2f}")
            
            with col2:
                if 'Aprobado' in cluster_data.columns:
                    aprob_rate = cluster_data['Aprobado'].mean() * 100
                    st.metric("Tasa de Aprobaci√≥n", f"{aprob_rate:.1f}%")
            
            # Determinar perfil
            if 'Nota_final' in cluster_data.columns:
                avg_grade = cluster_data['Nota_final'].mean()
                if avg_grade >= 80:
                    st.success("üéØ **Estudiantes Destacados**: Alto rendimiento acad√©mico")
                elif avg_grade >= 70:
                    st.info("üìö **Estudiantes Regulares**: Rendimiento satisfactorio")
                elif avg_grade >= 60:
                    st.warning("‚ö†Ô∏è **Estudiantes en Riesgo**: Requieren atenci√≥n")
                else:
                    st.error("üö® **Estudiantes Cr√≠ticos**: Necesitan intervenci√≥n inmediata")

# ============================================================================
# SECCI√ìN 4: COMPARACI√ìN
# ============================================================================
elif section == "üìà Comparaci√≥n":
    st.header("üìà Comparaci√≥n de Modelos")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üîÆ Modelo Supervisado")
        st.markdown("""
        ### ‚úÖ Ventajas:
        - **Alta precisi√≥n predictiva** para clasificaci√≥n
        - **Interpretaci√≥n directa** de variables importantes
        - **Probabilidades espec√≠ficas** por estudiante
        - **√ötil para intervenciones tempranas** y personalizadas
        
        ### ‚ö†Ô∏è Limitaciones:
        - **Requiere datos etiquetados** previamente
        - **Asume relaci√≥n lineal** entre variables
        - **Sensible a desbalance** de clases
        - **Puede sobreajustarse** a datos hist√≥ricos
        
        ### üéØ Mejor uso:
        **Predicci√≥n individualizada** de riesgo acad√©mico
        """)
    
    with col2:
        st.subheader("üîç Modelo No Supervisado")
        st.markdown("""
        ### ‚úÖ Ventajas:
        - **Descubre patrones ocultos** sin etiquetas previas
        - **Identifica perfiles naturales** de estudiantes
        - **√ötil para segmentaci√≥n** y personalizaci√≥n
        - **Detecta outliers** y casos at√≠picos
        
        ### ‚ö†Ô∏è Limitaciones:
        - **Dif√≠cil evaluaci√≥n objetiva** de resultados
        - **Sensible a selecci√≥n** de caracter√≠sticas
        - **Requiere interpretaci√≥n** experta
        - **Necesita definir** n√∫mero de clusters
        
        ### üéØ Mejor uso:
        **Segmentaci√≥n para estrategias** pedag√≥gicas diferenciadas
        """)
    
    st.markdown("---")
    
    # Integraci√≥n recomendada
    st.subheader("üöÄ Integraci√≥n Recomendada")
    
    st.info("""
    ### **Estrategia combinada para m√°xima efectividad:**
    
    1. **Primero usar Clustering** para identificar grupos naturales de estudiantes
    2. **Luego aplicar Clasificaci√≥n** dentro de cada grupo para predecir riesgo espec√≠fico
    3. **Dise√±ar intervenciones personalizadas** seg√∫n el grupo y riesgo predicho
    
    ### **Ejemplo de aplicaci√≥n:**
    
    | Cluster | Perfil | Estrategia Recomendada |
    |---------|---------|-----------------------|
    | 0 | üéØ Destacados | Mentor√≠a avanzada, oportunidades investigaci√≥n |
    | 1 | üìö Regulares | Refuerzo en √°reas espec√≠ficas, seguimiento regular |
    | 2 | ‚ö†Ô∏è En Riesgo | Tutor√≠as intensivas, seguimiento cercano |
    | 3 | üö® Cr√≠ticos | Intervenci√≥n inmediata, apoyo integral |
    
    ### **Beneficios:**
    - **Mayor precisi√≥n**: Modelos espec√≠ficos por grupo
    - **Intervenciones efectivas**: Estrategias personalizadas
    - **Uso eficiente de recursos**: Enfoque en quienes m√°s lo necesitan
    - **Prevenci√≥n temprana**: Identificaci√≥n proactiva de riesgo
    """)

# ============================================================================
# SECCI√ìN 5: PREDICCI√ìN
# ============================================================================
else:
    st.header("üîÆ Predicci√≥n Individual")
    
    # Verificar que tenemos datos con variable objetivo
    if 'Aprobado' not in df_clean.columns:
        st.error("No se puede realizar predicci√≥n - falta variable objetivo")
        st.info("Ve a la secci√≥n 'Modelo Supervisado' primero para configurar el l√≠mite de aprobaci√≥n")
        st.stop()
    
    # Verificar que tenemos ambas clases
    if df_clean['Aprobado'].nunique() < 2:
        st.warning("No hay suficientes clases para entrenar modelo predictivo")
        st.info("Ajusta el l√≠mite de aprobaci√≥n en la secci√≥n 'Modelo Supervisado'")
        st.stop()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Caracter√≠sticas del Estudiante")
        
        # Sliders con valores por defecto realistas
        asistencia = st.slider("Asistencia (%)", 0, 100, 85)
        tareas = st.slider("Tareas entregadas", 0, 30, 15)
        participacion = st.slider("Participaci√≥n (0-10)", 0, 10, 7)
        horas_estudio = st.slider("Horas de estudio semanales", 0, 40, 12)
        
        # Bot√≥n para predecir
        predecir = st.button("üîÆ Predecir Resultado", type="primary")
    
    with col2:
        # Preparar caracter√≠sticas para modelo
        numeric_features = df_clean.select_dtypes(include=[np.number]).columns.tolist()
        
        # Excluir columnas no relevantes
        exclude_features = ['Aprobado']
        for col in df_clean.columns:
            if 'nota' in col.lower() or 'Nota' in col:
                exclude_features.append(col)
        
        features = [col for col in numeric_features if col not in exclude_features]
        
        if len(features) == 0:
            st.error("No hay caracter√≠sticas para entrenar modelo")
            st.stop()
        
        # Entrenar modelo con todas las caracter√≠sticas disponibles
        X = df_clean[features]
        y = df_clean['Aprobado']
        
        # Verificar que tenemos datos
        if len(X) == 0:
            st.error("No hay datos para entrenar el modelo")
            st.stop()
        
        # Estandarizar
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Entrenar modelo
        model = LogisticRegression(random_state=42, max_iter=1000)
        model.fit(X_scaled, y)
        
        # Crear datos del estudiante (asegurar todas las caracter√≠sticas)
        estudiante_data = {}
        for feature in features:
            if feature == 'Asistencia':
                estudiante_data[feature] = asistencia
            elif feature == 'Tareas_entregadas' or 'tarea' in feature.lower():
                estudiante_data[feature] = tareas
            elif 'participacion' in feature.lower():
                estudiante_data[feature] = participacion
            elif 'hora' in feature.lower() or 'estudio' in feature.lower():
                estudiante_data[feature] = horas_estudio
            else:
                # Para otras caracter√≠sticas, usar la mediana
                estudiante_data[feature] = df_clean[feature].median()
        
        estudiante_df = pd.DataFrame([estudiante_data])
        
        # Asegurar el mismo orden de columnas
        estudiante_df = estudiante_df[features]
        
        # Estandarizar
        estudiante_scaled = scaler.transform(estudiante_df)
        
        # Predecir solo cuando se presiona el bot√≥n
        if predecir:
            try:
                probabilidad = model.predict_proba(estudiante_scaled)[0]
                prediccion = model.predict(estudiante_scaled)[0]
                
                st.subheader("Resultado de la Predicci√≥n")
                
                # Mostrar resultado con estilo
                if prediccion == 1:
                    st.success("""
                    ## ‚úÖ **APROBADO**
                    
                    **El estudiante tiene alta probabilidad de aprobar la asignatura.**
                    """)
                    st.balloons()
                else:
                    st.error("""
                    ## ‚ùå **REPROBADO**
                    
                    **El estudiante tiene alta probabilidad de reprobar la asignatura.**
                    **Se recomienda intervenci√≥n inmediata.**
                    """)
                
                # Mostrar probabilidades
                col_prob1, col_prob2 = st.columns(2)
                with col_prob1:
                    st.metric("Probabilidad de Aprobar", f"{probabilidad[1]*100:.1f}%")
                with col_prob2:
                    st.metric("Probabilidad de Reprobado", f"{probabilidad[0]*100:.1f}%")
                
                # Gr√°fico de probabilidades
                fig = px.bar(x=['Reprobado', 'Aprobado'], 
                            y=[probabilidad[0], probabilidad[1]],
                            color=['Reprobado', 'Aprobado'],
                            color_discrete_map={'Reprobado': '#EF553B', 'Aprobado': '#00CC96'},
                            labels={'x': 'Resultado', 'y': 'Probabilidad'},
                            title='Distribuci√≥n de Probabilidades',
                            text=[f'{probabilidad[0]*100:.1f}%', f'{probabilidad[1]*100:.1f}%'])
                fig.update_traces(textposition='outside')
                st.plotly_chart(fig, use_container_width=True)
                
                # Recomendaciones basadas en predicci√≥n
                st.subheader("üìã Recomendaciones")
                
                if prediccion == 0:  # Si predice reprobado
                    st.warning("""
                    **Acciones recomendadas:**
                    
                    1. **Revisar asistencia**: Asegurar m√≠nimo 80% de asistencia
                    2. **Entrega de tareas**: Completar todas las asignaciones pendientes
                    3. **Tutor√≠as**: Solicitar sesiones de refuerzo con el docente
                    4. **Horas de estudio**: Incrementar a m√≠nimo 15 horas semanales
                    5. **Seguimiento**: Programar evaluaci√≥n de progreso en 2 semanas
                    """)
                else:
                    st.info("""
                    **Acciones de mantenimiento:**
                    
                    1. **Continuar con buen desempe√±o**: Mantener h√°bitos de estudio
                    2. **Participaci√≥n activa**: Seguir participando en clases
                    3. **Ayuda a compa√±eros**: Ofrecer apoyo a estudiantes con dificultades
                    4. **Explorar profundizaci√≥n**: Buscar temas avanzados de inter√©s
                    """)
                
                # Factores de influencia
                if hasattr(model, 'coef_'):
                    importancia = np.abs(model.coef_[0])
                    idx_importante = np.argmax(importancia)
                    variable_importante = features[idx_importante]
                    
                    st.info(f"""
                    **Factor m√°s influyente en la predicci√≥n:**
                    ### **{variable_importante}**
                    
                    Mejorar en esta variable aumentar√≠a significativamente 
                    las probabilidades de aprobar.
                    """)
            
            except Exception as e:
                st.error(f"‚ùå Error al realizar predicci√≥n: {str(e)}")
        
        else:
            # Mostrar placeholder cuando no se ha presionado el bot√≥n
            st.subheader("Resultado de la Predicci√≥n")
            st.info("üëà Ajusta las caracter√≠sticas del estudiante y presiona 'Predecir Resultado'")
            
            # Mostrar valores actuales
            st.write("**Valores actuales:**")
            st.write(f"- Asistencia: {asistencia}%")
            st.write(f"- Tareas entregadas: {tareas}")
            st.write(f"- Participaci√≥n: {participacion}/10")
            st.write(f"- Horas de estudio: {horas_estudio} horas/semana")

# ============================================================================
# PIE DE P√ÅGINA
# ============================================================================
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>üìö Pr√°ctica de Aprendizaje Autom√°tico - Modelos Supervisado y No Supervisado</p>
    <p>üéì An√°lisis Predictivo del Rendimiento Acad√©mico</p>
    <p>‚öôÔ∏è Desarrollado con Python, Scikit-learn y Streamlit</p>
</div>
""", unsafe_allow_html=True)

# Debug info en sidebar (solo en desarrollo)
debug_mode = st.sidebar.checkbox("Modo debug", value=False)
if debug_mode:
    st.sidebar.write("### Debug Info")
    st.sidebar.write(f"Secci√≥n actual: {section}")
    st.sidebar.write(f"Tama√±o dataset original: {df.shape if 'df' in locals() else 'N/A'}")
    st.sidebar.write(f"Tama√±o dataset limpio: {df_clean.shape if 'df_clean' in locals() else 'N/A'}")
    
    if 'df_clean' in locals():
        st.sidebar.write("Columnas df_clean:", list(df_clean.columns))
        
        if 'Aprobado' in df_clean.columns:
            st.sidebar.write("Distribuci√≥n de Aprobado:")
            st.sidebar.write(df_clean['Aprobado'].value_counts())