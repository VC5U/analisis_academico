import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
from sklearn.cluster import KMeans
import plotly.express as px
import plotly.graph_objects as go
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="An√°lisis Acad√©mico - ML",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("üéì An√°lisis Predictivo del Rendimiento Acad√©mico")
st.markdown("""
**Modelos Supervisado y No Supervisado** para predecir y entender el rendimiento estudiantil
""")

# ============================================================================
# FUNCIONES PARA CARGAR Y PREPARAR DATOS
# ============================================================================
@st.cache_data
def cargar_datos():
    """Cargar dataset y entender su estructura"""
    try:
        df = pd.read_csv('academic_performance_master.csv')
        
        # Informaci√≥n b√°sica para debug
        st.session_state['dataset_info'] = {
            'filas': df.shape[0],
            'columnas': df.shape[1],
            'columnas_lista': df.columns.tolist()
        }
        
        return df
    except Exception as e:
        st.error(f"‚ùå Error al cargar dataset: {str(e)}")
        return None

@st.cache_data
def preparar_datos_para_modelos(df, limite_aprobacion=7.0):
    """Preparar datos para modelos ML"""
    df_clean = df.copy()
    
    # 1. Manejar valores nulos
    for col in df_clean.columns:
        if df_clean[col].isnull().sum() > 0:
            if df_clean[col].dtype == 'object':
                df_clean[col].fillna('Desconocido', inplace=True)
            else:
                df_clean[col].fillna(df_clean[col].median(), inplace=True)
    
    # 2. Crear variable objetivo (APROBADO/REPROBADO)
    if 'Nota_final' in df_clean.columns:
        # Verificar escala de notas
        nota_max = df_clean['Nota_final'].max()
        
        # Determinar escala (0-10 o 0-100)
        if nota_max <= 10:
            escala = "0-10"
            if limite_aprobacion > 10:
                limite_aprobacion = 7.0
                st.sidebar.info(f"üìù Notas en escala 0-10. L√≠mite ajustado a {limite_aprobacion}")
        else:
            escala = "0-100"
        
        df_clean['Aprobado'] = (df_clean['Nota_final'] >= limite_aprobacion).astype(int)
        
        # Estad√≠sticas
        aprobados = df_clean['Aprobado'].sum()
        total = len(df_clean)
        tasa_aprobacion = aprobados / total * 100
        
        return df_clean, 'Nota_final', limite_aprobacion, aprobados, total, tasa_aprobacion, escala
    else:
        st.error("‚ùå No se encontr√≥ columna 'Nota_final' en el dataset")
        return None, None, None, None, None, None, None

@st.cache_data
def crear_features_adicionales(df):
    """Crear caracter√≠sticas adicionales para mejorar modelos"""
    df_features = df.copy()
    
    # Si hay m√∫ltiples registros por estudiante, podemos agregar
    if 'Identificacion_Estudiante' in df.columns:
        stats_estudiante = df.groupby('Identificacion_Estudiante').agg({
            'Asistencia': 'mean',
            'Nota_final': 'mean',
            'Asignatura': 'count'
        }).rename(columns={
            'Asistencia': 'Asistencia_promedio',
            'Nota_final': 'Nota_promedio',
            'Asignatura': 'Num_asignaturas'
        }).reset_index()
        
        df_features = df_features.merge(stats_estudiante, 
                                      on='Identificacion_Estudiante', 
                                      how='left')
    
    # Codificar variables categ√≥ricas importantes
    categorical_cols = ['Nivel', 'Carrera']
    for col in categorical_cols:
        if col in df_features.columns:
            le = LabelEncoder()
            df_features[f'{col}_encoded'] = le.fit_transform(df_features[col].astype(str))
    
    return df_features

# ============================================================================
# SIDEBAR CONFIGURACI√ìN
# ============================================================================
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2232/2232688.png", width=100)
    st.title("üîç Navegaci√≥n")
    
    section = st.radio(
        "Selecciona una secci√≥n:",
        ["üìä Exploraci√≥n de Datos", 
         "ü§ñ Modelo Supervisado", 
         "üîç Modelo No Supervisado",
         "üìà Comparaci√≥n",
         "üîÆ Predicci√≥n"]
    )
    
    st.markdown("---")
    st.title("‚öôÔ∏è Configuraci√≥n")
    
    # Configuraci√≥n general
    usar_features_adicionales = st.checkbox("Usar caracter√≠sticas adicionales", value=True)
    
    if section == "ü§ñ Modelo Supervisado":
        st.subheader("Configuraci√≥n Modelo")
        test_size = st.slider("Tama√±o conjunto prueba:", 0.1, 0.5, 0.3, 0.05)
        
        # Detectar escala de notas
        df_loaded = cargar_datos()
        if df_loaded is not None and 'Nota_final' in df_loaded.columns:
            nota_max = df_loaded['Nota_final'].max()
            if nota_max <= 10:
                limite_default = 7.0
                limite_min, limite_max, step = 0.0, 10.0, 0.5
            else:
                limite_default = 70.0
                limite_min, limite_max, step = 0.0, 100.0, 5.0
            
            limite_aprobacion = st.slider("L√≠mite para aprobar:", 
                                         limite_min, limite_max, 
                                         limite_default, step)
        else:
            limite_aprobacion = st.slider("L√≠mite para aprobar:", 0.0, 100.0, 70.0, 5.0)
        
    elif section == "üîç Modelo No Supervisado":
        st.subheader("Configuraci√≥n Clustering")
        n_clusters = st.slider("N√∫mero de clusters:", 2, 6, 3)
    
    st.markdown("---")
    st.title("üìä Informaci√≥n del Dataset")
    
    # Cargar y mostrar informaci√≥n del dataset
    df = cargar_datos()
    
    if df is not None:
        # Filtrar carreras no deseadas
        if 'Carrera' in df.columns:
            # Contar antes de filtrar
            total_antes = len(df)
            
            # Filtrar carreras no deseadas
            mascara_carreras = df['Carrera'].astype(str).str.startswith(('PREPARAREC', 'NT', 'CENTRO DE IDIOM'))
            df = df[~mascara_carreras].copy()
            
            total_despues = len(df)
            eliminados = total_antes - total_despues
            
            if eliminados > 0:
                st.success(f"‚úÖ Dataset filtrado: {total_despues:,} registros")
                st.info(f"üóëÔ∏è Se eliminaron {eliminados:,} registros de carreras no deseadas")
            else:
                st.success(f"‚úÖ Dataset: {total_despues:,} registros")
        else:
            st.success(f"‚úÖ Dataset: {len(df):,} registros")
        
        # Informaci√≥n b√°sica
        with st.expander("Ver detalles del dataset"):
            st.write("**Columnas disponibles:**")
            st.write(df.columns.tolist())
            
            if 'Nota_final' in df.columns:
                st.write("**Estad√≠sticas de Nota_final:**")
                st.write(df['Nota_final'].describe())
                
                # Detectar escala
                nota_max = df['Nota_final'].max()
                if nota_max <= 10:
                    st.info("üìù **Escala detectada:** 0-10")
                else:
                    st.info("üìù **Escala detectada:** 0-100")
    else:
        st.error("No se pudo cargar el dataset")

# ============================================================================
# CARGAR Y PREPARAR DATOS
# ============================================================================
if 'df' not in locals() or df is None:
    df = cargar_datos()

if df is not None:
    # Aplicar filtro de carreras
    if 'Carrera' in df.columns:
        df = df[~df['Carrera'].astype(str).str.startswith(('PREPARAREC', 'NT', 'CENTRO DE IDIOM'))].copy()
    
    # Preparar datos seg√∫n configuraci√≥n
    if section == "ü§ñ Modelo Supervisado":
        df_clean, nota_col, limite, aprobados, total, tasa, escala = preparar_datos_para_modelos(
            df, limite_aprobacion if 'limite_aprobacion' in locals() else 7.0
        )
    else:
        df_clean, nota_col, limite, aprobados, total, tasa, escala = preparar_datos_para_modelos(df, 7.0)
    
    # Crear caracter√≠sticas adicionales si est√° habilitado
    if usar_features_adicionales and df_clean is not None:
        df_clean = crear_features_adicionales(df_clean)
else:
    st.error("‚ùå No se pudo cargar el dataset")
    st.stop()

# ============================================================================
# SECCI√ìN 1: EXPLORACI√ìN DE DATOS
# ============================================================================
if section == "üìä Exploraci√≥n de Datos":
    st.header("üìä Exploraci√≥n del Dataset")
    
    if df is not None:
        # Pesta√±as
        tab1, tab2, tab3, tab4 = st.tabs(["üìã Vista General", "üìà An√°lisis Estad√≠stico", 
                                          "üéì An√°lisis Acad√©mico", "üîç Calidad de Datos"])
        
        with tab1:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.subheader("Primeros registros")
                st.dataframe(df.head(10), use_container_width=True, height=350)
                
                st.subheader("Resumen por estudiante")
                if 'Identificacion_Estudiante' in df.columns:
                    estudiantes_unicos = df['Identificacion_Estudiante'].nunique()
                    asignaturas_por_est = df.groupby('Identificacion_Estudiante')['Asignatura'].count()
                    
                    col_est1, col_est2, col_est3 = st.columns(3)
                    with col_est1:
                        st.metric("Estudiantes √∫nicos", estudiantes_unicos)
                    with col_est2:
                        st.metric("Registros totales", len(df))
                    with col_est3:
                        st.metric("Prom. asignaturas/est", f"{asignaturas_por_est.mean():.1f}")
            
            with col2:
                st.subheader("Informaci√≥n General")
                st.metric("Total Registros", len(df))
                st.metric("Total Columnas", len(df.columns))
                
                if 'Nota_final' in df.columns:
                    nota_prom = df['Nota_final'].mean()
                    st.metric("Nota Promedio", f"{nota_prom:.2f}")
                    
                    # Distribuci√≥n de estados
                    if 'Estado_Asignatura' in df.columns:
                        estados = df['Estado_Asignatura'].value_counts()
                        st.write("**Estado de Asignaturas:**")
                        for estado, count in estados.items():
                            porcentaje = count/len(df)*100
                            st.write(f"- {estado}: {count} ({porcentaje:.1f}%)")
        
        with tab2:
            col1, col2 = st.columns(2)
            
            with col1:
                # Histograma de notas
                if 'Nota_final' in df.columns:
                    fig_notas = px.histogram(df, x='Nota_final', nbins=30,
                                            title='Distribuci√≥n de Notas Finales',
                                            color_discrete_sequence=['#636EFA'])
                    fig_notas.update_layout(xaxis_title="Nota Final", yaxis_title="Frecuencia")
                    st.plotly_chart(fig_notas, use_container_width=True)
                    
                    # Estad√≠sticas
                    st.subheader("Estad√≠sticas de Notas")
                    stats_df = df['Nota_final'].describe()
                    st.dataframe(pd.DataFrame(stats_df).T, use_container_width=True)
            
            with col2:
                # Boxplot de asistencia
                if 'Asistencia' in df.columns:
                    fig_asist = px.box(df, y='Asistencia', 
                                      title='Distribuci√≥n de Asistencia',
                                      color_discrete_sequence=['#00CC96'])
                    st.plotly_chart(fig_asist, use_container_width=True)
                    
                    # Relaci√≥n asistencia-nota (SIN trendline para evitar error)
                    if 'Nota_final' in df.columns:
                        fig_rel = px.scatter(df, x='Asistencia', y='Nota_final',
                                           title='Relaci√≥n: Asistencia vs Nota Final',
                                           opacity=0.6,
                                           trendline=None)  # Sin trendline
                        st.plotly_chart(fig_rel, use_container_width=True)
                        
                        # Calcular correlaci√≥n manualmente
                        correlacion = df['Asistencia'].corr(df['Nota_final'])
                        st.info(f"**Correlaci√≥n Asistencia-Nota:** {correlacion:.3f}")
            
            # Matriz de correlaci√≥n
            st.subheader("Matriz de Correlaci√≥n")
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            if len(numeric_cols) > 1:
                corr_matrix = df[numeric_cols].corr()
                
                fig_corr = px.imshow(corr_matrix, 
                                    text_auto='.2f',
                                    aspect="auto",
                                    color_continuous_scale='RdBu',
                                    title='Correlaci√≥n entre Variables Num√©ricas')
                st.plotly_chart(fig_corr, use_container_width=True)
        
        with tab3:
            st.subheader("üéì An√°lisis Acad√©mico Detallado")
            
            # An√°lisis por carrera
            if 'Carrera' in df.columns:
                st.write("**Desempe√±o por Carrera (Top 15):**")
                carrera_stats = df.groupby('Carrera').agg({
                    'Nota_final': ['mean', 'count'],
                    'Asistencia': 'mean'
                }).round(2)
                
                carrera_stats.columns = ['Nota_promedio', 'Num_registros', 'Asistencia_promedio']
                
                # Ordenar y mostrar
                carrera_stats = carrera_stats.sort_values('Nota_promedio', ascending=False).head(15)
                st.dataframe(carrera_stats, use_container_width=True)
                
                # Gr√°fico de barras por carrera
                fig_carrera = px.bar(carrera_stats.reset_index(),
                                    x='Carrera', y='Nota_promedio',
                                    title='Top 15 Carreras por Nota Promedio',
                                    color='Nota_promedio',
                                    color_continuous_scale='Viridis')
                fig_carrera.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig_carrera, use_container_width=True)
            
            # An√°lisis por nivel
            if 'Nivel' in df.columns:
                st.write("**Desempe√±o por Nivel Acad√©mico:**")
                nivel_stats = df.groupby('Nivel').agg({
                    'Nota_final': 'mean',
                    'Asistencia': 'mean',
                    'Identificacion_Estudiante': 'nunique'
                }).round(2)
                
                nivel_stats.columns = ['Nota_promedio', 'Asistencia_promedio', 'Estudiantes_unicos']
                st.dataframe(nivel_stats, use_container_width=True)
        
        with tab4:
            col1, col2 = st.columns(2)
            
            with col1:
                # Valores nulos
                st.subheader("Valores Nulos")
                null_counts = df.isnull().sum()
                null_df = pd.DataFrame({
                    'Columna': null_counts.index,
                    'Valores Nulos': null_counts.values,
                    '% Nulos': (null_counts.values / len(df) * 100).round(2)
                })
                null_df = null_df[null_df['Valores Nulos'] > 0]
                
                if len(null_df) > 0:
                    st.dataframe(null_df, use_container_width=True)
                    st.warning(f"‚ö†Ô∏è {len(null_df)} columnas tienen valores nulos")
                else:
                    st.success("‚úÖ No hay valores nulos")
            
            with col2:
                # Duplicados
                st.subheader("Registros Duplicados")
                dup_count = df.duplicated().sum()
                
                if dup_count > 0:
                    st.error(f"‚ùå {dup_count} registros duplicados")
                else:
                    st.success("‚úÖ No hay duplicados")
                
                # Valores √∫nicos
                st.subheader("Valores √önicos por Columna")
                unique_counts = df.nunique()
                unique_df = pd.DataFrame({
                    'Columna': unique_counts.index,
                    'Valores √önicos': unique_counts.values
                }).sort_values('Valores √önicos', ascending=False).head(10)
                st.dataframe(unique_df, use_container_width=True)
    
    else:
        st.error("No hay datos para mostrar")

# ============================================================================
# SECCI√ìN 2: MODELO SUPERVISADO
# ============================================================================
elif section == "ü§ñ Modelo Supervisado":
    st.header("ü§ñ Modelo de Clasificaci√≥n Supervisada")
    
    if df_clean is not None:
        # Mostrar informaci√≥n
        st.info(f"""
        **üìä Informaci√≥n del Dataset Preparado:**
        - Total registros: {total:,}
        - Aprobados: {aprobados:,} ({tasa:.1f}%)
        - L√≠mite de aprobaci√≥n: {limite}
        - Escala de notas: {escala}
        """)
        
        # Verificar que tenemos ambas clases
        if df_clean['Aprobado'].nunique() < 2:
            st.error(f"""
            ‚ö†Ô∏è **PROBLEMA**: Solo hay una clase en los datos
            
            **Soluci√≥n:**
            1. Ajusta el l√≠mite de aprobaci√≥n en la barra lateral
            2. Actualmente usando l√≠mite: {limite}
            3. Rango de notas: {df_clean['Nota_final'].min():.1f} - {df_clean['Nota_final'].max():.1f}
            """)
            
            # Mostrar distribuci√≥n de notas
            fig_dist = px.histogram(df_clean, x='Nota_final', nbins=30,
                                   title=f'Distribuci√≥n de Notas (L√≠mite: {limite})',
                                   color_discrete_sequence=['#FF6B6B'])
            fig_dist.add_vline(x=limite, line_dash="dash", line_color="green",
                              annotation_text=f"L√≠mite: {limite}")
            st.plotly_chart(fig_dist, use_container_width=True)
            st.stop()
        
        # Preparar caracter√≠sticas
        st.subheader("üéØ Selecci√≥n de Caracter√≠sticas")
        
        numeric_features = df_clean.select_dtypes(include=[np.number]).columns.tolist()
        exclude_features = ['Aprobado', 'Nota_final']
        if 'Nota_promedio' in numeric_features:
            exclude_features.append('Nota_promedio')
        
        features = [col for col in numeric_features if col not in exclude_features]
        
        if len(features) == 0:
            st.error("No hay caracter√≠sticas num√©ricas disponibles")
            st.stop()
        
        st.success(f"‚úÖ {len(features)} caracter√≠sticas seleccionadas")
        
        # Dividir datos
        X = df_clean[features]
        y = df_clean['Aprobado']
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        # Estandarizar
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entrenar modelo
        st.subheader("üöÄ Entrenamiento del Modelo")
        
        with st.spinner("Entrenando modelo..."):
            try:
                model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')
                model.fit(X_train_scaled, y_train)
                
                # Predicciones
                y_pred = model.predict(X_test_scaled)
                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
                
                # M√©tricas
                accuracy = accuracy_score(y_test, y_pred)
                conf_matrix = confusion_matrix(y_test, y_pred)
                roc_auc = roc_auc_score(y_test, y_pred_proba)
                
                st.success("‚úÖ Modelo entrenado exitosamente!")
                
                # Mostrar m√©tricas
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Accuracy", f"{accuracy:.2%}")
                
                with col2:
                    precision = conf_matrix[1,1] / (conf_matrix[1,1] + conf_matrix[0,1]) if (conf_matrix[1,1] + conf_matrix[0,1]) > 0 else 0
                    st.metric("Precisi√≥n", f"{precision:.2%}")
                
                with col3:
                    recall = conf_matrix[1,1] / (conf_matrix[1,1] + conf_matrix[1,0]) if (conf_matrix[1,1] + conf_matrix[1,0]) > 0 else 0
                    st.metric("Recall", f"{recall:.2%}")
                
                with col4:
                    st.metric("ROC-AUC", f"{roc_auc:.3f}")
                
                # Matriz de confusi√≥n
                st.subheader("üìä Matriz de Confusi√≥n")
                
                fig_cm = px.imshow(conf_matrix,
                                  text_auto=True,
                                  color_continuous_scale='Blues',
                                  labels=dict(x="Predicci√≥n", y="Real", color="Cantidad"),
                                  x=['Reprobado', 'Aprobado'],
                                  y=['Reprobado', 'Aprobado'],
                                  title=f'Accuracy: {accuracy:.2%}')
                st.plotly_chart(fig_cm, use_container_width=True)
                
                # Reporte
                st.subheader("üìã Reporte de Clasificaci√≥n")
                report = classification_report(y_test, y_pred, output_dict=True)
                report_df = pd.DataFrame(report).transpose()
                st.dataframe(report_df, use_container_width=True)
                
                # Importancia de caracter√≠sticas
                st.subheader("üîù Importancia de Caracter√≠sticas")
                
                if hasattr(model, 'coef_'):
                    importance = pd.DataFrame({
                        'Caracter√≠stica': features,
                        'Importancia': np.abs(model.coef_[0])
                    }).sort_values('Importancia', ascending=False)
                    
                    fig_imp = px.bar(importance.head(15), 
                                    x='Importancia', 
                                    y='Caracter√≠stica',
                                    orientation='h',
                                    title='Top 15 Caracter√≠sticas M√°s Importantes',
                                    color='Importancia',
                                    color_continuous_scale='Viridis')
                    st.plotly_chart(fig_imp, use_container_width=True)
                    
                    st.dataframe(importance, use_container_width=True)
                
                # Curva ROC
                st.subheader("üìà Curva ROC")
                
                fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
                
                fig_roc = go.Figure()
                fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', 
                                            name=f'ROC (AUC = {roc_auc:.3f})',
                                            line=dict(color='blue', width=2)))
                fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines',
                                            name='L√≠nea base', line=dict(dash='dash', color='gray')))
                
                fig_roc.update_layout(title='Curva ROC',
                                     xaxis_title='Tasa de Falsos Positivos',
                                     yaxis_title='Tasa de Verdaderos Positivos')
                
                st.plotly_chart(fig_roc, use_container_width=True)
                
            except Exception as e:
                st.error(f"‚ùå Error al entrenar modelo: {str(e)}")
    else:
        st.error("No hay datos preparados para el modelo")

# ============================================================================
# SECCI√ìN 3: MODELO NO SUPERVISADO
# ============================================================================
elif section == "üîç Modelo No Supervisado":
    st.header("üîç Clustering de Estudiantes")
    
    if df_clean is not None:
        st.info(f"üìä Dataset: {len(df_clean):,} registros")
        
        # Seleccionar caracter√≠sticas para clustering
        available_features = ['Asistencia', 'Nota_final']
        X_cluster = df_clean[available_features].copy()
        X_cluster = X_cluster.dropna()
        
        if len(X_cluster) < n_clusters:
            st.error(f"No hay suficientes datos ({len(X_cluster)}) para {n_clusters} clusters")
            st.stop()
        
        # M√©todo del codo
        st.subheader("üìâ M√©todo del Codo")
        
        inertias = []
        k_range = range(1, 11)
        
        for k in k_range:
            kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans_temp.fit(X_cluster)
            inertias.append(kmeans_temp.inertia_)
        
        fig_elbow = px.line(x=list(k_range), y=inertias,
                           title='M√©todo del Codo - Inercia vs N√∫mero de Clusters',
                           labels={'x': 'N√∫mero de Clusters (K)', 'y': 'Inercia'},
                           markers=True)
        fig_elbow.add_vline(x=n_clusters, line_dash="dash", line_color="red",
                           annotation_text=f"K seleccionado = {n_clusters}")
        st.plotly_chart(fig_elbow, use_container_width=True)
        
        # Aplicar K-means
        st.subheader(f"üé® Visualizaci√≥n de Clusters (K={n_clusters})")
        
        with st.spinner(f"Aplicando K-means..."):
            scaler_cluster = StandardScaler()
            X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)
            
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(X_cluster_scaled)
            
            df_viz = pd.DataFrame({
                'Asistencia': X_cluster['Asistencia'],
                'Nota_final': X_cluster['Nota_final'],
                'Cluster': clusters
            })
        
        # Gr√°fico de clusters
        fig_clusters = px.scatter(df_viz, x='Asistencia', y='Nota_final',
                                 color='Cluster', 
                                 title='Clustering: Asistencia vs Nota Final',
                                 color_continuous_scale='viridis',
                                 opacity=0.7)
        
        # A√±adir centroides
        centroids_descaled = scaler_cluster.inverse_transform(kmeans.cluster_centers_)
        centroids_df = pd.DataFrame(centroids_descaled, columns=available_features)
        
        fig_clusters.add_trace(go.Scatter(
            x=centroids_df['Asistencia'],
            y=centroids_df['Nota_final'],
            mode='markers',
            marker=dict(symbol='x', size=15, color='red', line=dict(width=2)),
            name='Centroides'
        ))
        
        st.plotly_chart(fig_clusters, use_container_width=True)
        
        # Estad√≠sticas por cluster
        st.subheader("üìä Estad√≠sticas por Cluster")
        
        if 'Aprobado' in df_clean.columns:
            df_viz = df_viz.merge(df_clean[['Aprobado']], left_index=True, right_index=True)
            stats_cols = ['Asistencia', 'Nota_final', 'Aprobado']
        else:
            stats_cols = ['Asistencia', 'Nota_final']
        
        cluster_stats = df_viz.groupby('Cluster')[stats_cols].agg(['mean', 'std', 'count']).round(2)
        
        # Formatear tabla
        stats_display = pd.DataFrame()
        for col in stats_cols:
            for stat in ['mean', 'std']:
                if (col, stat) in cluster_stats.columns:
                    stats_display[f'{col}_{stat}'] = cluster_stats[(col, stat)]
        
        st.dataframe(stats_display, use_container_width=True)
        
        # Interpretaci√≥n
        st.subheader("üë• Interpretaci√≥n de Clusters")
        
        cluster_counts = df_viz['Cluster'].value_counts().sort_index()
        
        for cluster_id in range(n_clusters):
            with st.expander(f"Cluster {cluster_id} - {cluster_counts.get(cluster_id, 0)} estudiantes"):
                cluster_data = df_viz[df_viz['Cluster'] == cluster_id]
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**Caracter√≠sticas promedio:**")
                    asist_prom = cluster_data['Asistencia'].mean()
                    nota_prom = cluster_data['Nota_final'].mean()
                    st.write(f"‚Ä¢ **Asistencia**: {asist_prom:.1f}%")
                    st.write(f"‚Ä¢ **Nota final**: {nota_prom:.2f}")
                
                with col2:
                    if 'Aprobado' in cluster_data.columns:
                        aprob_rate = cluster_data['Aprobado'].mean() * 100
                        st.metric("Tasa de Aprobaci√≥n", f"{aprob_rate:.1f}%")
                
                # Determinar perfil
                if 'Nota_final' in cluster_data.columns:
                    nota_prom = cluster_data['Nota_final'].mean()
                    
                    if nota_prom >= 8.5:
                        st.success("**üéØ PERFIL: EXCELENTES** - Alto rendimiento")
                    elif nota_prom >= 7.0:
                        st.info("**üìö PERFIL: BUENOS** - Rendimiento satisfactorio")
                    elif nota_prom >= 6.0:
                        st.warning("**‚ö†Ô∏è PERFIL: REGULARES** - Necesita mejora")
                    else:
                        st.error("**üö® PERFIL: CR√çTICOS** - Intervenci√≥n urgente")
    
    else:
        st.error("No hay datos para clustering")

# ============================================================================
# SECCI√ìN 4: COMPARACI√ìN
# ============================================================================
elif section == "üìà Comparaci√≥n":
    st.header("üìà Comparaci√≥n de Modelos")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ü§ñ Modelo Supervisado")
        st.markdown("""
        ### ‚úÖ **Fortalezas:**
        - **Alta precisi√≥n predictiva** para clasificaci√≥n binaria
        - **Interpretaci√≥n directa** de variables importantes  
        - **Probabilidades espec√≠ficas** por estudiante
        - **Ideal para intervenciones** tempranas y personalizadas
        
        ### ‚ö†Ô∏è **Limitaciones:**
        - Requiere **datos etiquetados** previamente
        - Asume **relaci√≥n lineal** entre variables
        - Sensible a **desbalance** de clases
        - Puede **sobreajustarse** a patrones hist√≥ricos
        
        ### üéØ **Mejor uso:**
        **Predicci√≥n individualizada** de riesgo acad√©mico
        """)
    
    with col2:
        st.subheader("üîç Modelo No Supervisado")
        st.markdown("""
        ### ‚úÖ **Fortalezas:**
        - **Descubre patrones ocultos** sin necesidad de etiquetas
        - **Identifica perfiles naturales** de estudiantes
        - **√ötil para segmentaci√≥n** y personalizaci√≥n de estrategias
        - **Detecta outliers** y casos at√≠picos autom√°ticamente
        
        ### ‚ö†Ô∏è **Limitaciones:**
        - **Dif√≠cil evaluaci√≥n objetiva** de resultados
        - **Sensible a selecci√≥n** de caracter√≠sticas
        - **Requiere interpretaci√≥n** experta de clusters
        - Necesita **definir n√∫mero** de clusters manualmente
        
        ### üéØ **Mejor uso:**
        **Segmentaci√≥n estrat√©gica** para pedagog√≠a diferenciada
        """)
    
    st.markdown("---")
    
    # Integraci√≥n recomendada
    st.subheader("üöÄ Integraci√≥n Recomendada")
    
    st.info("""
    ### **Estrategia combinada para m√°xima efectividad:**
    
    1. **Primero usar Clustering** para identificar **grupos naturales** de estudiantes
    2. **Luego aplicar Clasificaci√≥n** dentro de cada grupo para **predecir riesgo espec√≠fico**
    3. **Dise√±ar intervenciones personalizadas** seg√∫n el **grupo + riesgo predicho**
    
    ### **Ejemplo de aplicaci√≥n pr√°ctica:**
    
    | Cluster | Perfil | Estrategia Recomendada |
    |---------|---------|-----------------------|
    | **0** | üéØ **Destacados** | Mentor√≠a avanzada, oportunidades investigaci√≥n |
    | **1** | üìö **Regulares** | Refuerzo espec√≠fico, seguimiento regular |
    | **2** | ‚ö†Ô∏è **En Riesgo** | Tutor√≠as intensivas, plan de mejora |
    | **3** | üö® **Cr√≠ticos** | Intervenci√≥n inmediata, apoyo integral |
    """)

# ============================================================================
# SECCI√ìN 5: PREDICCI√ìN
# ============================================================================
else:
    st.header("üîÆ Predicci√≥n Individual")
    
    if df_clean is not None and 'Aprobado' in df_clean.columns:
        # Entrenar modelo r√°pido para predicci√≥n
        numeric_features = df_clean.select_dtypes(include=[np.number]).columns.tolist()
        exclude_features = ['Aprobado', 'Nota_final']
        if 'Nota_promedio' in numeric_features:
            exclude_features.append('Nota_promedio')
        
        features_pred = [col for col in numeric_features if col not in exclude_features]
        
        if len(features_pred) == 0:
            st.error("No hay caracter√≠sticas para entrenar modelo predictivo")
            st.stop()
        
        X_pred = df_clean[features_pred]
        y_pred = df_clean['Aprobado']
        
        # Verificar que tenemos ambas clases
        if y_pred.nunique() < 2:
            st.error("No hay suficientes clases para entrenar modelo predictivo")
            st.info("Ajusta el l√≠mite de aprobaci√≥n en la secci√≥n 'Modelo Supervisado'")
            st.stop()
        
        # Entrenar modelo
        scaler_pred = StandardScaler()
        X_pred_scaled = scaler_pred.fit_transform(X_pred)
        
        model_pred = LogisticRegression(random_state=42, max_iter=1000)
        model_pred.fit(X_pred_scaled, y_pred)
        
        col_input, col_result = st.columns([1, 1])
        
        with col_input:
            st.subheader("üìù Caracter√≠sticas del Estudiante")
            
            # Inputs basados en caracter√≠sticas disponibles
            inputs = {}
            
            if 'Asistencia' in features_pred:
                asistencia = st.slider("Asistencia (%)", 0, 100, 85)
                inputs['Asistencia'] = asistencia
            
            if 'Participacion_clase' in features_pred:
                participacion = st.slider("Participaci√≥n (0-10)", 0, 10, 7)
                inputs['Participacion_clase'] = participacion
            
            # Bot√≥n para predecir
            if st.button("üéØ Predecir Resultado", type="primary", use_container_width=True):
                # Crear datos del estudiante
                estudiante_data = {}
                for feature in features_pred:
                    if feature in inputs:
                        estudiante_data[feature] = inputs[feature]
                    else:
                        estudiante_data[feature] = df_clean[feature].median()
                
                estudiante_df = pd.DataFrame([estudiante_data])
                estudiante_df = estudiante_df[features_pred]
                
                # Estandarizar y predecir
                estudiante_scaled = scaler_pred.transform(estudiante_df)
                probabilidad = model_pred.predict_proba(estudiante_scaled)[0]
                prediccion = model_pred.predict(estudiante_scaled)[0]
                
                # Guardar resultados
                st.session_state['prediccion_resultados'] = {
                    'probabilidad': probabilidad,
                    'prediccion': prediccion,
                    'caracteristicas': inputs
                }
        
        with col_result:
            st.subheader("üìä Resultado de Predicci√≥n")
            
            if 'prediccion_resultados' in st.session_state:
                resultados = st.session_state['prediccion_resultados']
                
                # Calcular probabilidades
                prob_reprobado = resultados['probabilidad'][0] * 100
                prob_aprobado = resultados['probabilidad'][1] * 100
                
                if resultados['prediccion'] == 1:
                    st.success(f"""
                    ## ‚úÖ **APROBADO**
                    
                    **Probabilidad de aprobar:** {prob_aprobado:.1f}%
                    
                    El estudiante tiene **alta probabilidad** de aprobar.
                    """)
                    st.balloons()
                else:
                    st.error(f"""
                    ## ‚ùå **REPROBADO**
                    
                    **Probabilidad de reprobar:** {prob_reprobado:.1f}%
                    
                    El estudiante tiene **alta probabilidad** de reprobar.
                    **Se recomienda intervenci√≥n inmediata.**
                    """)
                
                # Gr√°fico de probabilidades
                fig_pred = px.bar(x=['Reprobado', 'Aprobado'], 
                                y=[resultados['probabilidad'][0], resultados['probabilidad'][1]],
                                color=['Reprobado', 'Aprobado'],
                                color_discrete_map={'Reprobado': '#EF553B', 'Aprobado': '#00CC96'},
                                labels={'x': 'Resultado', 'y': 'Probabilidad'},
                                title='Distribuci√≥n de Probabilidades',
                                text=[f'{prob_reprobado:.1f}%', f'{prob_aprobado:.1f}%'])
                fig_pred.update_traces(textposition='outside')
                st.plotly_chart(fig_pred, use_container_width=True)
                
                # Recomendaciones
                st.subheader("üìã Recomendaciones")
                
                if resultados['prediccion'] == 0:
                    st.warning("""
                    **üî¥ ACCIONES RECOMENDADAS (URGENTE):**
                    
                    1. **üìÖ Revisar asistencia** - Asegurar m√≠nimo 80% de asistencia
                    2. **üìö Entrega de tareas** - Completar asignaciones pendientes
                    3. **üë®‚Äçüè´ Tutor√≠as** - Solicitar sesiones de refuerzo inmediatas
                    4. **‚è∞ Horas de estudio** - Incrementar horas de estudio
                    5. **üìä Seguimiento** - Evaluaci√≥n de progreso en 2 semanas
                    """)
                else:
                    st.info("""
                    **üü¢ ACCIONES DE MANTENIMIENTO:**
                    
                    1. **‚úÖ Continuar buen desempe√±o** - Mantener h√°bitos de estudio
                    2. **üí¨ Participaci√≥n activa** - Seguir participando en clases
                    3. **ü§ù Ayuda a compa√±eros** - Ofrecer apoyo a estudiantes
                    4. **üéØ Explorar profundizaci√≥n** - Buscar temas avanzados
                    """)
            else:
                st.info("üëà Ajusta las caracter√≠sticas y presiona 'Predecir Resultado'")
    else:
        st.error("No hay datos preparados para predicci√≥n")

# ============================================================================
# PIE DE P√ÅGINA
# ============================================================================
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>üìö <b>Pr√°ctica de Aprendizaje Autom√°tico</b> - Modelos Supervisado y No Supervisado</p>
    <p>üéì <b>An√°lisis Predictivo del Rendimiento Acad√©mico</b></p>
    <p>‚öôÔ∏è Desarrollado con Python, Scikit-learn y Streamlit</p>
    <p>üìÖ Diciembre 2025</p>
</div>
""", unsafe_allow_html=True)